{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature extraction through GRU\n",
    "# input = characteristics of stocks as input\n",
    "# output = latent vector of stocks\n",
    "'''\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_latent, hidden_size, num_layers=1):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.num_latent = num_latent\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.normalize = nn.LayerNorm(num_latent)\n",
    "        self.linear = nn.Linear(num_latent, num_latent)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.gru = nn.GRU(num_latent, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #! x: (batch_size, seq_length, num_latent)\n",
    "        # Apply linear and LeakyReLU activation\n",
    "        #* add layer norm\n",
    "        x = self.normalize(x)\n",
    "        out = self.linear(x)\n",
    "        out = self.leakyrelu(out)\n",
    "        # Forward propagate GRU\n",
    "        stock_latent, _ = self.gru(out)\n",
    "        return stock_latent[:,-1,:] #* stock_latent[-1]: (batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorEncoder(nn.Module):\n",
    "    def __init__(self, num_factors, num_portfolio, hidden_size):\n",
    "        super(FactorEncoder, self).__init__()\n",
    "        self.num_factors = num_factors\n",
    "        self.linear = nn.Linear(hidden_size, num_portfolio)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.linear2 = nn.Linear(num_portfolio, num_factors)\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    def mapping_layer(self, portfolio_return):\n",
    "        #! portfolio_return: (batch_size, 1)\n",
    "        #! mapping layer\n",
    "        # print(portfolio_return.shape)\n",
    "        mean = self.linear2(portfolio_return.squeeze(1))\n",
    "        sigma = self.softplus(mean)\n",
    "        return mean, sigma\n",
    "    \n",
    "    def forward(self, stock_latent, returns):\n",
    "        #! stock_latent: (batch_size, hidden_size)\n",
    "        #! returns: (batch_size, 1) （仅一期回报率）\n",
    "        #! make portfolio\n",
    "        weights = self.linear(stock_latent)\n",
    "        weights = self.softmax(weights) # (batch_size, num_portfolio)\n",
    "\n",
    "        # multiply weights and returns\n",
    "        #print(f\"weights shape: {weights.shape}, returns shape: {returns.shape}\") # [300, 20], [300, 1]\n",
    "        # check returns.shape is tuple\n",
    "        if returns.dim() == 1:\n",
    "            returns = returns.unsqueeze(1)\n",
    "        portfolio_return = torch.mm(weights.transpose(1,0), returns) #* portfolio_return: (M, 1)\n",
    "        #print(f\"portfolio_return shape: {portfolio_return.shape}\")\n",
    "        \n",
    "        return self.mapping_layer(portfolio_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaLayer(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AlphaLayer, self).__init__()\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.mu_layer = nn.Linear(hidden_size, 1)\n",
    "        self.sigma_layer = nn.Linear(hidden_size, 1)\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    def forward(self, stock_latent):\n",
    "        #* stock latent from FeatureExtractor (batch_size, hidden_size)\n",
    "        stock_latent = self.linear1(stock_latent)\n",
    "        stock_latent = self.leakyrelu(stock_latent)\n",
    "        alpha_mu = self.mu_layer(stock_latent)\n",
    "        alpha_sigma = self.sigma_layer(stock_latent)\n",
    "        return alpha_mu, self.softplus(alpha_sigma)\n",
    "        \n",
    "class BetaLayer(nn.Module):\n",
    "    \"\"\"calcuate factor exposure beta(N*K)\"\"\"\n",
    "    def __init__(self, hidden_size, num_factors):\n",
    "        super(BetaLayer, self).__init__()\n",
    "        self.linear1 = nn.Linear(hidden_size, num_factors)\n",
    "    \n",
    "    def forward(self, stock_latent):\n",
    "        beta = self.linear1(stock_latent)\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorDecoder(nn.Module):\n",
    "    def __init__(self, alpha_layer, beta_layer):\n",
    "        super(FactorDecoder, self).__init__()\n",
    "\n",
    "        self.alpha_layer = alpha_layer\n",
    "        self.beta_layer = beta_layer\n",
    "    \n",
    "    def reparameterize(self, mu, sigma):\n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + eps * sigma\n",
    "    \n",
    "    def forward(self, stock_latent, factor_mu, factor_sigma):\n",
    "        #! warning: alpha_mu, alpha_sigma -> (N), (N)\n",
    "        alpha_mu, alpha_sigma = self.alpha_layer(stock_latent)\n",
    "        #print(f\"alpha_mu shape: {alpha_mu.shape}, alpha_sigma shape: {alpha_sigma.shape}\")\n",
    "        beta = self.beta_layer(stock_latent)\n",
    "\n",
    "        factor_mu = factor_mu.view(-1, 1)\n",
    "        factor_sigma = factor_sigma.view(-1, 1)\n",
    "\n",
    "        # Replace any zero values in factor_sigma with a small value\n",
    "        factor_sigma[factor_sigma == 0] = 1e-6\n",
    "        #print(f\"factor_mu shape: {factor_mu.shape}, factor_sigma shape: {factor_sigma.shape}\")\n",
    "        #print(f\"beta shape: {beta.shape}\")\n",
    "        mu = alpha_mu + torch.matmul(beta, factor_mu)\n",
    "        sigma = torch.sqrt(alpha_sigma**2 + torch.matmul(beta**2, factor_sigma**2) + 1e-6)\n",
    "\n",
    "        return self.reparameterize(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        \n",
    "        self.query = nn.Parameter(torch.randn(hidden_size))\n",
    "        self.key_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, stock_latent):\n",
    "        #* calculate attention weights\n",
    "\n",
    "        self.key = self.key_layer(stock_latent)\n",
    "        self.value = self.value_layer(stock_latent)\n",
    "        \n",
    "        attention_weights = torch.matmul(self.query, self.key.transpose(1,0)) # (N)\n",
    "        #* scaling\n",
    "        attention_weights = attention_weights / torch.sqrt(torch.tensor(self.key.shape[0])+ 1e-6)\n",
    "        # print(f\"attention_weights shape: {attention_weights.shape}\")\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        attention_weights = F.relu(attention_weights) # max(0, x)\n",
    "        attention_weights = F.softmax(attention_weights, dim=0) # (N)\n",
    "        \n",
    "        #! calculate context vector\n",
    "        if torch.isnan(attention_weights).any() or torch.isinf(attention_weights).any():\n",
    "            return torch.zeros_like(self.value[0])\n",
    "        else:\n",
    "            context_vector = torch.matmul(attention_weights, self.value) # (H)\n",
    "            return context_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorPredictor(nn.Module):\n",
    "    def __init__(self, batch_size, hidden_size, num_factor):\n",
    "        super(FactorPredictor, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_factor = num_factor\n",
    "        self.attention_layers = nn.ModuleList([AttentionLayer(self.hidden_size) for _ in range(num_factor)])\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.mu_layer = nn.Linear(hidden_size, 1)\n",
    "        self.sigma_layer = nn.Linear(hidden_size, 1)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, stock_latent):\n",
    "        #! only input stock latent (N, H)\n",
    "        \n",
    "        for i in range(self.num_factor):\n",
    "            attention_layer = self.attention_layers[i](stock_latent)\n",
    "            if i == 0:\n",
    "                h_multi = attention_layer\n",
    "            else:\n",
    "                h_multi = torch.cat((h_multi, attention_layer), dim=0)\n",
    "        h_multi = h_multi.view(self.num_factor, -1)\n",
    "\n",
    "        # print(\"h_multi:\", h_multi.shape)\n",
    "        h_multi = self.linear(h_multi)\n",
    "        h_multi = self.leakyrelu(h_multi)\n",
    "        pred_mu = self.mu_layer(h_multi)\n",
    "        pred_sigma = self.sigma_layer(h_multi)\n",
    "        pred_sigma = self.softplus(pred_sigma)\n",
    "        pred_mu = pred_mu.view(-1)\n",
    "        pred_sigma = pred_sigma.view(-1)\n",
    "        return pred_mu, pred_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorVAE(nn.Module):\n",
    "    def __init__(self, feature_extractor, factor_encoder, factor_decoder, factor_predictor):\n",
    "        super(FactorVAE, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.factor_encoder = factor_encoder\n",
    "        self.factor_decoder = factor_decoder\n",
    "        self.factor_predictor = factor_predictor\n",
    "\n",
    "    @staticmethod\n",
    "    def KL_Divergence(mu1, sigma1, mu2, sigma2):\n",
    "        #! mu1, mu2: (batch_size, 1)\n",
    "        #! sigma1, sigma2: (batch_size, 1)\n",
    "        #! output: (batch_size, 1)\n",
    "        kl_div = (torch.log(sigma2/ sigma1) + (sigma1**2 + (mu1 - mu2)**2) / (2 * sigma2**2) - 0.5).sum()\n",
    "        return kl_div\n",
    "\n",
    "    def forward(self, x, returns):\n",
    "        #! x: (batch_size, seq_length, num_latent)\n",
    "        #! returns: (batch_size, 1)\n",
    "\n",
    "        stock_latent = self.feature_extractor(x)\n",
    "        factor_mu, factor_sigma = self.factor_encoder(stock_latent, returns)\n",
    "        reconstruction = self.factor_decoder(stock_latent, factor_mu, factor_sigma)\n",
    "        pred_mu, pred_sigma = self.factor_predictor(stock_latent)\n",
    "\n",
    "        # print(f\"pred_mu: {pred_mu.shape}, pred_sigma: {pred_sigma.shape}\")\n",
    "        # Define VAE loss function with reconstruction loss and KL divergence\n",
    "        #* Some adjustment\n",
    "        #* stock_adj: number of stocks that have no return data\n",
    "        stock_adj = 0\n",
    "        for i in range(len(returns)-1,-1,-1):\n",
    "            if returns[i] == 0:\n",
    "                stock_adj += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if stock_adj > 0:\n",
    "            reconstruction_loss = F.mse_loss(reconstruction[:-stock_adj], returns[:-stock_adj])\n",
    "        else:\n",
    "            reconstruction_loss = F.mse_loss(reconstruction, returns)\n",
    "            \n",
    "        # Calculate KL divergence between two Gaussian distributions\n",
    "        if torch.any(pred_sigma == 0):\n",
    "            pred_sigma[pred_sigma == 0] = 1e-6\n",
    "        kl_divergence = self.KL_Divergence(factor_mu, factor_sigma, pred_mu, pred_sigma)\n",
    "\n",
    "        vae_loss = reconstruction_loss + kl_divergence\n",
    "        # print(\"loss: \", vae_loss)\n",
    "        return vae_loss, reconstruction, factor_mu, factor_sigma, pred_mu, pred_sigma #! reconstruction, factor_mu, factor_sigma\n",
    "\n",
    "    # use after learning\n",
    "    def prediction(self, x):\n",
    "        stock_latent = self.feature_extractor(x)\n",
    "        pred_mu, pred_sigma = self.factor_predictor(stock_latent)\n",
    "        y_pred = self.factor_decoder(stock_latent, pred_mu, pred_sigma)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4432, grad_fn=<AddBackward0>) tensor([-0.0811, -0.0636,  0.0983, -0.0238, -0.3046,  0.1630,  0.6381, -0.1649],\n",
      "       grad_fn=<AddBackward0>) tensor([0.6534, 0.6618, 0.7435, 0.6813, 0.5524, 0.7780, 1.0623, 0.6141],\n",
      "       grad_fn=<CopySlices>) tensor([-0.1104, -0.1169, -0.1247, -0.1170, -0.1124, -0.1260, -0.1598, -0.1044],\n",
      "       grad_fn=<ViewBackward0>) tensor([0.7266, 0.7027, 0.6798, 0.7032, 0.7078, 0.7015, 0.6944, 0.7123],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_latent = 20\n",
    "batch_size = 300 # equal to num of stocks\n",
    "seq_len = 30\n",
    "num_factor = 8\n",
    "hidden_size = 20\n",
    "\n",
    "test_char = torch.randn(batch_size, seq_len, num_latent) # (batch_size, seq_length, num_latent)\n",
    "test_returns = torch.randn(batch_size, 1) # (batch_size, 1)\n",
    "\n",
    "feature_extractor = FeatureExtractor(num_latent = num_latent, hidden_size =hidden_size)\n",
    "stock_latent = feature_extractor(test_char)\n",
    "\n",
    "factor_encoder = FactorEncoder(num_factors=num_factor, num_portfolio=num_latent, hidden_size=hidden_size)\n",
    "alpha_layer = AlphaLayer(hidden_size)\n",
    "beta_layer = BetaLayer(hidden_size, num_factor)\n",
    "factor_decoder = FactorDecoder(alpha_layer, beta_layer)\n",
    "factor_predictor = FactorPredictor(batch_size, hidden_size, num_factor)\n",
    "factorVAE = FactorVAE(feature_extractor, factor_encoder, factor_decoder, factor_predictor)\n",
    "\n",
    "vae_loss, reconstruction, factor_mu, factor_sigma, pred_mu, pred_sigma = factorVAE(test_char, test_returns)\n",
    "\n",
    "print(vae_loss, factor_mu, factor_sigma, pred_mu, pred_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_char = torch.randn(batch_size, seq_len, num_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 30, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
