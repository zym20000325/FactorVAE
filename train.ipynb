{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "from factorvae import FactorVAE, FeatureExtractor, FactorDecoder, FactorEncoder, FactorPredictor, AlphaLayer, BetaLayer\n",
    "from dataset import StockDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'batch_size': 300,\n",
    "    'seq_len': 20,\n",
    "    'num_latent': 158,\n",
    "    'hidden_size': 20,\n",
    "    'num_factor': 8,\n",
    "    'lr': 0.0005,\n",
    "    'num_epochs': 25\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('data/train.pkl')\n",
    "df_valid = pd.read_pickle('data/valid.pkl')\n",
    "df_test = pd.read_pickle('data/test.pkl')\n",
    "\n",
    "df_train.columns = df_train.columns.droplevel(level=0)\n",
    "df_valid.columns = df_valid.columns.droplevel(level=0)\n",
    "df_test.columns = df_test.columns.droplevel(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = StockDataset(df_train, args['batch_size'], args['seq_len'])\n",
    "ds_valid = StockDataset(df_valid, args['batch_size'], args['seq_len'])\n",
    "ds_test = StockDataset(df_test, args['batch_size'], args['seq_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ds_train, batch_size=300, shuffle=False)\n",
    "valid_dataloader = DataLoader(ds_valid, batch_size=300, shuffle=False)\n",
    "test_dataloader = DataLoader(ds_test, batch_size=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dataloader = DataLoader(ds_valid, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1951,  1.8856, -0.5353,  ...,  0.5397,  1.7871,  1.5821],\n",
      "         [ 0.0000, -1.7979,  0.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [-3.0000,  3.0000, -1.2462,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         ...,\n",
      "         [ 1.7401,  1.6219,  0.8395,  ...,  0.2356, -0.5692, -0.9325],\n",
      "         [ 0.0000,  1.0907,  0.0000,  ...,  2.3406,  2.8888,  3.0000],\n",
      "         [ 1.0017,  0.3257,  0.7783,  ..., -0.1469, -1.2197,  0.6544]]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([1, 20, 158])\n",
      "tensor([[0.0714, 0.1000, 0.1001, 0.1000, 0.0605, 0.1002, 0.0545, 0.0400, 0.0838,\n",
      "         0.1000, 0.0725, 0.0778, 0.0900, 0.0627, 0.1002, 0.1004, 0.1009, 0.0985,\n",
      "         0.0999, 0.0882]], dtype=torch.float64)\n",
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "for hist, futr in check_dataloader:\n",
    "    print(hist)\n",
    "    print(hist.shape)\n",
    "    print(futr)\n",
    "    print(futr.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Build FactorVAE Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(num_latent = args['num_latent'], hidden_size = args['hidden_size'])\n",
    "\n",
    "factor_encoder = FactorEncoder(num_factors = args['num_factor'], num_portfolio = args['num_latent'], hidden_size = args['hidden_size'])\n",
    "\n",
    "alpha_layer = AlphaLayer(args['hidden_size'])\n",
    "beta_layer = BetaLayer(args['hidden_size'], args['num_factor'])\n",
    "factor_decoder = FactorDecoder(alpha_layer, beta_layer)\n",
    "\n",
    "factor_predictor = FactorPredictor(args['batch_size'], args['hidden_size'], args['num_factor'])\n",
    "\n",
    "factorVAE = FactorVAE(feature_extractor, factor_encoder, factor_decoder, factor_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorVAE.to(device)\n",
    "\n",
    "best_val_loss = 10000.0\n",
    "optimizer = torch.optim.Adam(factorVAE.parameters(), lr = args['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = args['lr'], \\\n",
    "    steps_per_epoch = len(train_dataloader), epochs=args['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(factor_model, dataloader, optimizer, args):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    factor_model.to(device)\n",
    "    factor_model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(total=len(dataloader)-args['seq_len']+1) as pbar:\n",
    "\n",
    "        for char, returns in dataloader:\n",
    "            if char.shape[1] != args['seq_len']:\n",
    "                continue\n",
    "            inputs = char.to(device)\n",
    "            labels = returns[:,-1].reshape(-1,1).to(device)\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # print(inputs.shape)\n",
    "            # print(labels.shape)\n",
    "            loss, reconstruction, factor_mu, factor_sigma, pred_mu, pred_sigma = factor_model(inputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(1)\n",
    "        # print(loss)\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(factor_model, dataloader, args):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    factor_model.to(device)\n",
    "    factor_model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(total=len(dataloader)-args['seq_len']+1) as pbar:\n",
    "        for char, returns in dataloader:\n",
    "            if char.shape[1] != args['seq_len']:\n",
    "                continue\n",
    "            inputs = char.to(device)\n",
    "            labels = returns[:,-1].reshape(-1,1).to(device)\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            \n",
    "            loss, reconstruction, factor_mu, factor_sigma, pred_mu, pred_sigma = factor_model(inputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            pbar.update(1)\n",
    "            \n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:26<00:00,  8.08it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.23it/s]\n",
      "  4%|▍         | 1/25 [03:48<1:31:22, 228.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.3387, Validation Loss: 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:27<00:00,  8.06it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.41it/s]\n",
      "  8%|▊         | 2/25 [07:37<1:27:37, 228.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0502, Validation Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.14it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.41it/s]\n",
      " 12%|█▏        | 3/25 [11:23<1:23:29, 227.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0118, Validation Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:26<00:00,  8.09it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.27it/s]\n",
      " 16%|█▌        | 4/25 [15:11<1:19:45, 227.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0046, Validation Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:27<00:00,  8.06it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.39it/s]\n",
      " 20%|██        | 5/25 [19:00<1:16:04, 228.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0024, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.32it/s]\n",
      " 24%|██▍       | 6/25 [22:47<1:12:05, 227.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0015, Validation Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:24<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.29it/s]\n",
      " 28%|██▊       | 7/25 [26:33<1:08:11, 227.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0011, Validation Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.12it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.39it/s]\n",
      " 32%|███▏      | 8/25 [30:21<1:04:23, 227.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0009, Validation Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.13it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.40it/s]\n",
      " 36%|███▌      | 9/25 [34:08<1:00:34, 227.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0008, Validation Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.12it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.34it/s]\n",
      " 40%|████      | 10/25 [37:55<56:48, 227.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.40it/s]\n",
      " 44%|████▍     | 11/25 [41:41<52:58, 227.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:24<00:00,  8.16it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.40it/s]\n",
      " 48%|████▊     | 12/25 [45:28<49:07, 226.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.38it/s]\n",
      " 52%|█████▏    | 13/25 [49:14<45:20, 226.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.34it/s]\n",
      " 56%|█████▌    | 14/25 [53:01<41:33, 226.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.11it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.30it/s]\n",
      " 60%|██████    | 15/25 [56:48<37:49, 226.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.13it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.37it/s]\n",
      " 64%|██████▍   | 16/25 [1:00:35<34:02, 226.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:24<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.42it/s]\n",
      " 68%|██████▊   | 17/25 [1:04:22<30:14, 226.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.0007, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.14it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.39it/s]\n",
      " 72%|███████▏  | 18/25 [1:08:08<26:27, 226.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:24<00:00,  8.16it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.48it/s]\n",
      " 76%|███████▌  | 19/25 [1:11:55<22:39, 226.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:24<00:00,  8.16it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.48it/s]\n",
      " 80%|████████  | 20/25 [1:15:41<18:52, 226.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:25<00:00,  8.15it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.42it/s]\n",
      " 84%|████████▍ | 21/25 [1:19:27<15:05, 226.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:22<00:00,  8.24it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.61it/s]\n",
      " 88%|████████▊ | 22/25 [1:23:11<11:16, 225.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:15<00:00,  8.54it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.39it/s]\n",
      " 92%|█████████▏| 23/25 [1:26:48<07:26, 223.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:20<00:00,  8.32it/s]\n",
      "100%|██████████| 244/244 [00:20<00:00, 11.68it/s]\n",
      " 96%|█████████▌| 24/25 [1:30:30<03:42, 222.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1671/1671 [03:23<00:00,  8.21it/s]\n",
      "100%|██████████| 244/244 [00:21<00:00, 11.52it/s]\n",
      "100%|██████████| 25/25 [1:34:15<00:00, 226.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss: 0.0006, Validation Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(args['num_epochs'])):\n",
    "\n",
    "    train_loss = train(factorVAE, train_dataloader, optimizer, args)\n",
    "    val_loss = validate(factorVAE, valid_dataloader, args)\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\") \n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    " \n",
    "        torch.save(factorVAE.state_dict(), \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
